/**
 * Unified docs API handler for @farming-labs/fumadocs.
 *
 * A single route handler that serves **both** search and AI chat:
 *
 * - `GET  /api/docs?query=…` → full-text search over indexed MDX pages
 * - `POST /api/docs` → RAG-powered "Ask AI" (searches relevant docs,
 *   then streams an LLM response using the docs as context)
 *
 * This replaces the old `createDocsSearchAPI` — one handler, one route.
 *
 * @example
 * ```ts
 * // app/api/docs/route.ts (auto-generated by withDocs)
 * import { createDocsAPI } from "@farming-labs/fumadocs/api";
 * export const { GET, POST } = createDocsAPI();
 * export const revalidate = false;
 * ```
 */

import fs from "node:fs";
import path from "node:path";
import matter from "gray-matter";
import { createSearchAPI } from "fumadocs-core/search/server";

// ─── Types ──────────────────────────────────────────────────────────

interface SearchIndex {
  title: string;
  description?: string;
  content: string;
  url: string;
}

interface AIOptions {
  enabled?: boolean;
  model?: string;
  systemPrompt?: string;
  baseUrl?: string;
  apiKeyEnv?: string;
  maxResults?: number;
}

interface DocsAPIOptions {
  /** Docs entry folder (default: read from docs.config) */
  entry?: string;
  /** Search language (default: "english") */
  language?: string;
  /** AI chat configuration */
  ai?: AIOptions;
}

// ─── Helpers ────────────────────────────────────────────────────────

const FILE_EXTS = ["tsx", "ts", "jsx", "js"];

function readEntry(root: string): string {
  for (const ext of FILE_EXTS) {
    const configPath = path.join(root, `docs.config.${ext}`);
    if (fs.existsSync(configPath)) {
      try {
        const content = fs.readFileSync(configPath, "utf-8");
        const match = content.match(/entry\s*:\s*["']([^"']+)["']/);
        if (match) return match[1];
      } catch {
        // fall through
      }
    }
  }
  return "docs";
}

/**
 * Read AI config from docs.config by parsing the file for the `ai` block.
 * This avoids importing the config (which may use JSX/React).
 */
function readAIConfig(root: string): AIOptions {
  for (const ext of FILE_EXTS) {
    const configPath = path.join(root, `docs.config.${ext}`);
    if (fs.existsSync(configPath)) {
      try {
        const content = fs.readFileSync(configPath, "utf-8");

        // Check if AI is enabled
        if (!content.includes("ai:") && !content.includes("ai :")) {
          return {};
        }

        const enabledMatch = content.match(
          /ai\s*:\s*\{[^}]*enabled\s*:\s*(true|false)/s,
        );
        if (enabledMatch && enabledMatch[1] === "false") return {};

        const modelMatch = content.match(
          /ai\s*:\s*\{[^}]*model\s*:\s*["']([^"']+)["']/s,
        );
        const baseUrlMatch = content.match(
          /ai\s*:\s*\{[^}]*baseUrl\s*:\s*["']([^"']+)["']/s,
        );
        const apiKeyEnvMatch = content.match(
          /ai\s*:\s*\{[^}]*apiKeyEnv\s*:\s*["']([^"']+)["']/s,
        );
        const maxResultsMatch = content.match(
          /ai\s*:\s*\{[^}]*maxResults\s*:\s*(\d+)/s,
        );
        const systemPromptMatch = content.match(
          /ai\s*:\s*\{[^}]*systemPrompt\s*:\s*["'`]([^"'`]+)["'`]/s,
        );

        return {
          enabled: true,
          model: modelMatch?.[1],
          baseUrl: baseUrlMatch?.[1],
          apiKeyEnv: apiKeyEnvMatch?.[1],
          maxResults: maxResultsMatch ? parseInt(maxResultsMatch[1], 10) : undefined,
          systemPrompt: systemPromptMatch?.[1],
        };
      } catch {
        // fall through
      }
    }
  }
  return {};
}

function stripMdx(raw: string): string {
  const { content } = matter(raw);
  return content
    .replace(/^(import|export)\s.*$/gm, "")
    .replace(/<[^>]+\/>/g, "")
    .replace(/<\/?[A-Z][^>]*>/g, "")
    .replace(/<\/?[a-z][^>]*>/g, "")
    .replace(/\[([^\]]+)\]\([^)]+\)/g, "$1")
    .replace(/!\[([^\]]*)\]\([^)]+\)/g, "$1")
    .replace(/^#{1,6}\s+/gm, "")
    .replace(/(\*{1,3}|_{1,3})(.*?)\1/g, "$2")
    .replace(/```[\s\S]*?```/g, "")
    .replace(/`([^`]+)`/g, "$1")
    .replace(/^>\s+/gm, "")
    .replace(/^[-*_]{3,}\s*$/gm, "")
    .replace(/\n{3,}/g, "\n\n")
    .trim();
}

function scanDocsDir(docsDir: string, entry: string): SearchIndex[] {
  const indexes: SearchIndex[] = [];

  function scan(dir: string, slugParts: string[]) {
    if (!fs.existsSync(dir)) return;

    const pagePath = path.join(dir, "page.mdx");
    if (fs.existsSync(pagePath)) {
      try {
        const raw = fs.readFileSync(pagePath, "utf-8");
        const { data } = matter(raw);
        const title =
          (data.title as string) ||
          slugParts[slugParts.length - 1]?.replace(/-/g, " ") ||
          "Documentation";
        const description = data.description as string | undefined;
        const content = stripMdx(raw);
        const url =
          slugParts.length === 0
            ? `/${entry}`
            : `/${entry}/${slugParts.join("/")}`;

        indexes.push({ title, description, content, url });
      } catch {
        // skip unreadable files
      }
    }

    let entries: string[];
    try {
      entries = fs.readdirSync(dir);
    } catch {
      return;
    }

    for (const name of entries.sort()) {
      const full = path.join(dir, name);
      try {
        if (fs.statSync(full).isDirectory()) {
          scan(full, [...slugParts, name]);
        }
      } catch {
        // skip
      }
    }
  }

  scan(docsDir, []);
  return indexes;
}

// ─── AI Chat (RAG) ─────────────────────────────────────────────────

const DEFAULT_SYSTEM_PROMPT = `You are a helpful documentation assistant. Answer questions based on the provided documentation context. Be concise and accurate. If the answer is not in the context, say so honestly. Use markdown formatting for code examples and links.`;

interface ChatMessage {
  role: "user" | "assistant" | "system";
  content: string;
}

async function handleAskAI(
  request: Request,
  indexes: SearchIndex[],
  searchServer: { search: (query: string) => Promise<unknown[]> },
  aiConfig: AIOptions,
): Promise<Response> {
  // ── Validate config ────────────────────────────────────────────
  const apiKeyEnv = aiConfig.apiKeyEnv ?? "OPENAI_API_KEY";
  const apiKey = process.env[apiKeyEnv];

  if (!apiKey) {
    return Response.json(
      {
        error: `AI is enabled but the ${apiKeyEnv} environment variable is not set. Set it in your .env.local file.`,
      },
      { status: 500 },
    );
  }

  // ── Parse request ──────────────────────────────────────────────
  let body: { messages?: ChatMessage[] };
  try {
    body = await request.json();
  } catch {
    return Response.json(
      { error: "Invalid JSON body. Expected { messages: [...] }" },
      { status: 400 },
    );
  }

  const messages = body.messages;
  if (!Array.isArray(messages) || messages.length === 0) {
    return Response.json(
      { error: "messages array is required and must not be empty." },
      { status: 400 },
    );
  }

  const lastUserMessage = [...messages].reverse().find((m) => m.role === "user");
  if (!lastUserMessage) {
    return Response.json(
      { error: "At least one user message is required." },
      { status: 400 },
    );
  }

  // ── Search for relevant docs (RAG retrieval) ───────────────────
  const maxResults = aiConfig.maxResults ?? 5;
  const query = lastUserMessage.content;

  // Use the in-memory index for fast context retrieval
  const scored = indexes
    .map((doc) => {
      const q = query.toLowerCase();
      const titleMatch = doc.title.toLowerCase().includes(q) ? 10 : 0;
      const contentWords = q.split(/\s+/);
      const contentMatch = contentWords.reduce((score, word) => {
        return score + (doc.content.toLowerCase().includes(word) ? 1 : 0);
      }, 0);
      return { ...doc, score: titleMatch + contentMatch };
    })
    .filter((d) => d.score > 0)
    .sort((a, b) => b.score - a.score)
    .slice(0, maxResults);

  // Build context from relevant docs
  const contextParts = scored.map(
    (doc) =>
      `## ${doc.title}\nURL: ${doc.url}\n${doc.description ? `Description: ${doc.description}\n` : ""}\n${doc.content}`,
  );
  const context = contextParts.join("\n\n---\n\n");

  // ── Build LLM messages ─────────────────────────────────────────
  const systemPrompt = aiConfig.systemPrompt ?? DEFAULT_SYSTEM_PROMPT;
  const systemMessage: ChatMessage = {
    role: "system",
    content: context
      ? `${systemPrompt}\n\n---\n\nDocumentation context:\n\n${context}`
      : systemPrompt,
  };

  const llmMessages: ChatMessage[] = [
    systemMessage,
    ...messages.filter((m) => m.role !== "system"),
  ];

  // ── Stream from LLM ────────────────────────────────────────────
  const baseUrl = (aiConfig.baseUrl ?? "https://api.openai.com/v1").replace(
    /\/$/,
    "",
  );
  const model = aiConfig.model ?? "gpt-4o-mini";

  const llmResponse = await fetch(`${baseUrl}/chat/completions`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model,
      stream: true,
      messages: llmMessages,
    }),
  });

  if (!llmResponse.ok) {
    const errText = await llmResponse.text().catch(() => "Unknown error");
    return Response.json(
      { error: `LLM API error (${llmResponse.status}): ${errText}` },
      { status: 502 },
    );
  }

  // Proxy the SSE stream directly to the client
  return new Response(llmResponse.body, {
    headers: {
      "Content-Type": "text/event-stream",
      "Cache-Control": "no-cache",
      Connection: "keep-alive",
    },
  });
}

// ─── createDocsAPI ──────────────────────────────────────────────────

/**
 * Create a unified docs API route handler.
 *
 * Returns `{ GET, POST }` for use in a Next.js route handler:
 * - **GET** → full-text search (same as the old `createDocsSearchAPI`)
 * - **POST** → AI-powered chat with RAG (when AI is enabled in config)
 *
 * @example
 * ```ts
 * // app/api/docs/route.ts
 * import { createDocsAPI } from "@farming-labs/fumadocs/api";
 * export const { GET, POST } = createDocsAPI();
 * export const revalidate = false;
 * ```
 *
 * @param options - Optional overrides (entry, language, ai config)
 */
export function createDocsAPI(options?: DocsAPIOptions) {
  const root = process.cwd();
  const entry = options?.entry ?? readEntry(root);
  const docsDir = path.join(root, "app", entry);
  const language = options?.language ?? "english";

  // Read AI config from docs.config if not explicitly provided
  const aiConfig: AIOptions = options?.ai ?? readAIConfig(root);

  // Build search indexes (shared between search and AI)
  const indexes = scanDocsDir(docsDir, entry);

  // Create the fumadocs-core search API (provides GET handler)
  const searchAPI = createSearchAPI("simple" as const, {
    language,
    indexes,
  } as any);

  return {
    /**
     * GET handler — full-text search.
     * Query: `?query=search+term`
     */
    GET: searchAPI.GET,

    /**
     * POST handler — AI chat with RAG.
     * Body: `{ messages: [{ role: "user", content: "How do I …?" }] }`
     * Response: SSE stream of chat completion chunks.
     */
    async POST(request: Request): Promise<Response> {
      if (!aiConfig.enabled) {
        return Response.json(
          {
            error:
              "AI is not enabled. Set `ai: { enabled: true }` in your docs.config to enable it.",
          },
          { status: 404 },
        );
      }

      return handleAskAI(request, indexes, searchAPI, aiConfig);
    },
  };
}
